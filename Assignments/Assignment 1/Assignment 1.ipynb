{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment 1.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMvMkCcFjl1MlYTVC7je23T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["###Riyad Bin Rafiq\n","###03/25/2022"],"metadata":{"id":"E91PwXI-4vGa"}},{"cell_type":"markdown","source":["## Part A"],"metadata":{"id":"RjJsTBzgrKS0"}},{"cell_type":"code","source":["import os\n","import torch\n","import torch.utils.data as data\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torchvision.transforms as transforms \n","import cv2\n","import glob\n","import matplotlib.pyplot as plt\n","from tqdm.notebook import trange, tqdm\n","import torch.utils.data as data\n","import torch.optim as optim\n","import torch.nn.functional as F"],"metadata":{"id":"QXlHwYQV6jLY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-y8xUhEX7kc4","executionInfo":{"status":"ok","timestamp":1648305301924,"user_tz":300,"elapsed":57312,"user":{"displayName":"Riyad Bin Rafiq","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyQ935tH43wlvgBJOixHoW4DL--bYADihDRNyzCw=s64","userId":"11522088134831227343"}},"outputId":"10c56a88-a06e-4082-a7d8-6315b56e9adc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/My Drive/PhD courses/CSCE 5218 Deep Learning/Assignments/Assignment 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olKUf4OF82NX","executionInfo":{"status":"ok","timestamp":1648305306358,"user_tz":300,"elapsed":1426,"user":{"displayName":"Riyad Bin Rafiq","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyQ935tH43wlvgBJOixHoW4DL--bYADihDRNyzCw=s64","userId":"11522088134831227343"}},"outputId":"28381388-e836-429b-98ad-14d18329aa29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/PhD courses/CSCE 5218 Deep Learning/Assignments/Assignment 1\n"]}]},{"cell_type":"code","source":["!7z x 'cifar10.zip'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KGtaPGL17Gyk","executionInfo":{"status":"ok","timestamp":1648257115173,"user_tz":300,"elapsed":29957,"user":{"displayName":"Riyad Bin Rafiq","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyQ935tH43wlvgBJOixHoW4DL--bYADihDRNyzCw=s64","userId":"11522088134831227343"}},"outputId":"d81bcece-e65c-4107-8b42-2ed1f16f929c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n","p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n","\n","Scanning the drive for archives:\n","  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 147491716 bytes (141 MiB)\n","\n","Extracting archive: cifar10.zip\n","  6% 4096 Open\b\b\b\b\b\b\b\b\b\b\b\b\b\b              \b\b\b\b\b\b\b\b\b\b\b\b\b\b--\n","Path = cifar10.zip\n","Type = zip\n","Physical Size = 147491716\n","\n","  0%\b\b\b\b    \b\b\b\b\n","Would you like to replace the existing file:\n","  Path:     ./cifar10_train/frog/frog_00000.png\n","  Size:     2461 bytes (3 KiB)\n","  Modified: 2022-03-24 17:39:56\n","with the file from archive:\n","  Path:     cifar10_train/frog/frog_00000.png\n","  Size:     2461 bytes (3 KiB)\n","  Modified: 2020-02-08 01:02:05\n","? (Y)es / (N)o / (A)lways / (S)kip all / A(u)to rename all / (Q)uit? "]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GXOOZW41LSG_","executionInfo":{"status":"ok","timestamp":1648305311197,"user_tz":300,"elapsed":313,"user":{"displayName":"Riyad Bin Rafiq","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyQ935tH43wlvgBJOixHoW4DL--bYADihDRNyzCw=s64","userId":"11522088134831227343"}},"outputId":"8e058b29-e977-49fa-fa80-06767afae148"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'Assignment 1.ipynb'   cifar10_test   cifar10_train   cifar10.zip\n"]}]},{"cell_type":"code","source":["''' This function is used to store the image's paths and class names in two separate lists  '''\n","\n","def image_path_class_store(full_image_path):\n","  image_path = []\n","  classes = []\n","  for data_path in glob.glob(full_image_path + '/*'):\n","    classes.append(data_path.split('/')[-1]) \n","    image_path.append(glob.glob(data_path + '/*'))\n","  image_path_list = [item for sublist in image_path for item in sublist]\n","  return image_path_list, classes"],"metadata":{"id":"cSgOcTsCxUoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' The above function is used to separate paths and class names for train and test dataset '''\n","\n","train_image_path, train_classes = image_path_class_store('cifar10_train')\n","test_image_path, _ = image_path_class_store('cifar10_test')"],"metadata":{"id":"4K-NIUz5yPJX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_image_path)\n","print(test_image_path)\n","print(train_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1Rtp4uvhNLxr3F097Pu-9oaKMEZzoWIPm"},"id":"B9w9BS2syuMM","executionInfo":{"status":"ok","timestamp":1648305526755,"user_tz":300,"elapsed":1343,"user":{"displayName":"Riyad Bin Rafiq","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyQ935tH43wlvgBJOixHoW4DL--bYADihDRNyzCw=s64","userId":"11522088134831227343"}},"outputId":"c7f614fe-d4bc-4606-a2fb-83d529e06464"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["''' Each class has been assigned to a numeric label '''\n","\n","class_to_label = dict(frog=0, truck=1, deer=2, bird=3, horse=4, ship=5, cat=6, dog=7, automobile=8, airplane=9)"],"metadata":{"id":"eLXi0BcYyOfI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUVCAIMcqZb-"},"outputs":[],"source":["''' The CifarDataset is a custom dataset that has been used for preparaing the train and test data\n","    based on the passed arguments: path of image directory and image transformation. \n","'''\n","\n","class CifarDataset(Dataset):\n","    def __init__(self, image_paths, transform):\n","        self.image_paths = image_paths\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","      image_filepath = self.image_paths[idx]\n","      image = cv2.imread(image_filepath)\n","      image_class = image_filepath.split('/')[-2]\n","      label = class_to_label[image_class]\n","      image = self.transform(image)\n","      return image, label"]},{"cell_type":"code","source":["transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.Grayscale(num_output_channels=1)])"],"metadata":{"id":"OhP8xEwCARJH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = CifarDataset(train_image_path, transforms)\n","test_dataset = CifarDataset(test_image_path, transforms)"],"metadata":{"id":"sX1p-YbBXrvA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset[0][0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sPgQhZNbz18h","executionInfo":{"status":"ok","timestamp":1648305560043,"user_tz":300,"elapsed":1058,"user":{"displayName":"Riyad Bin Rafiq","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyQ935tH43wlvgBJOixHoW4DL--bYADihDRNyzCw=s64","userId":"11522088134831227343"}},"outputId":"abdd0ed1-02de-4b78-e773-ded940d710b6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 32, 32])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n","test_loader = DataLoader(test_dataset,batch_size=128, shuffle=False, num_workers=2)"],"metadata":{"id":"kzFz4GjlMvm8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Part B"],"metadata":{"id":"Ed0GPipmi1ef"}},{"cell_type":"code","source":["''' This is 3-layer MLP model (one input layer, one hidden layer and one output layer). '''\n","\n","class MultiLayerPerceptronModel(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super().__init__()\n","\n","        self.input_fc = nn.Linear(input_dim, 512)\n","        self.output_fc = nn.Linear(512, output_dim)\n","\n","    def forward(self, x):\n","        \n","        batch_size = x.shape[0]\n","        x = x.view(batch_size, -1)\n","        h = F.relu(self.input_fc(x))\n","        y_pred = self.output_fc(h)\n","\n","        return y_pred"],"metadata":{"id":"VxV8E4iI71QS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["INPUT_DIM = 32 * 32\n","OUTPUT_DIM = 10\n","\n","model = MultiLayerPerceptronModel(INPUT_DIM, OUTPUT_DIM)"],"metadata":{"id":"VIOudGjg8LsB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9TJDXLcqhJB","executionInfo":{"status":"ok","timestamp":1648305685334,"user_tz":300,"elapsed":398,"user":{"displayName":"Riyad Bin Rafiq","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyQ935tH43wlvgBJOixHoW4DL--bYADihDRNyzCw=s64","userId":"11522088134831227343"}},"outputId":"1b667609-ab54-4de5-b65c-f57de4d77c55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MultiLayerPerceptronModel(\n","  (input_fc): Linear(in_features=1024, out_features=512, bias=True)\n","  (output_fc): Linear(in_features=512, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","criterion = criterion.to(device)"],"metadata":{"id":"Ab-iN8u5uoSI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_accuracy(y_pred, y):\n","    top_pred = y_pred.argmax(1, keepdim=True)\n","    correct = top_pred.eq(y.view_as(top_pred)).sum()\n","    acc = correct.float() / y.shape[0]\n","    return acc"],"metadata":{"id":"S94Puf-9sL8W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' This train function is used to train the multilayer perceptron for specific number of epochs. '''\n","PATH = './cifar_net.pth'\n","\n","def train(epoch, model, loader, optimizer, criterion, device):\n","\n","    model.train()\n","  \n","    for iter in range(epoch):\n","      \n","      epoch_loss = 0\n","      epoch_acc = 0\n","      \n","      for i, data in enumerate(loader, 0):\n","        \n","        batch_loss = 0\n","        batch_acc = 0\n","\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        acc = calculate_accuracy(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        batch_loss += loss.item()\n","        batch_acc += acc.item()\n","        print('Batch Loss: ')\n","        print(f'\\tTrain Loss: {batch_loss/len(inputs):.3f} | Train Acc: {(batch_acc/len(inputs))*100:.2f}%')\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","      print(f'Epoch: {iter+1:02}')\n","      print(f'\\tFinal train Loss: {epoch_loss/len(loader):.3f} | Final train Acc: {(epoch_acc/len(loader))*100:.2f}%')\n","    # Saving the model \n","    torch.save(model.state_dict(), PATH)"],"metadata":{"id":"zJoTz5YCr_W5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' This function evaluate the trained model on the test set. '''\n","\n","def evaluation(model, loader):\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for data in loader:\n","            images, labels = data\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"],"metadata":{"id":"shuT4c4vr_ss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 1\n","\n","# Calling train function to train the network. It returns the final training loss and accuracy. \n","train(EPOCHS, model, train_loader, optimizer, criterion, device)\n","trained_model = model\n","trained_model = trained_model.to(device)\n","# Load the trained model\n","trained_model.load_state_dict(torch.load(PATH))\n","# Evaluatet the trained model on the test set\n","evaluation(trained_model, test_loader)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rRqJl75NsRAh","executionInfo":{"status":"ok","timestamp":1648329106107,"user_tz":300,"elapsed":3184199,"user":{"displayName":"Riyad Bin Rafiq","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiyQ935tH43wlvgBJOixHoW4DL--bYADihDRNyzCw=s64","userId":"11522088134831227343"}},"outputId":"838cc71f-673e-4e91-dd3f-b6e56660a5f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f38f1228710>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f38f1228710>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n","    if w.is_alive():\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n","    assert self._parent_pid == os.getpid(), 'can only test a child process'\n","AssertionError: can only test a child process\n"]},{"output_type":"stream","name":"stdout","text":["Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.43%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.41%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.41%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.46%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.41%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.41%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.44%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.43%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.43%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.41%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.49%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.30%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.43%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.43%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.28%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.46%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.41%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.43%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.43%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.41%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.43%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.27%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.014 | Train Acc: 0.29%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.27%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.29%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.41%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.45%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.014 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.45%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.30%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.41%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.45%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.41%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.43%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.45%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.44%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.30%\n","Batch Loss: \n","\tTrain Loss: 0.010 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.33%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.42%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.41%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.29%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.31%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.43%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.43%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.39%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.34%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.32%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.37%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.35%\n","Batch Loss: \n","\tTrain Loss: 0.012 | Train Acc: 0.36%\n","Batch Loss: \n","\tTrain Loss: 0.013 | Train Acc: 0.38%\n","Batch Loss: \n","\tTrain Loss: 0.011 | Train Acc: 0.40%\n","Batch Loss: \n","\tTrain Loss: 0.019 | Train Acc: 0.58%\n","Epoch: 01\n","\tFinal train Loss: 1.517 | Final train Acc: 47.25%\n","Accuracy of the network on the 10000 test images: 43 %\n"]}]}]}